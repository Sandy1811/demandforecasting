{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Time-Series Data\n"
     ]
    }
   ],
   "source": [
    "cd E:\\Time-Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n",
      "Training and predicting models...\n",
      "==================================================\n",
      "Step 1\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:0.8063\tval-rmse:0.774881\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 50 rounds.\n",
      "[50]\ttrain-rmse:0.557188\tval-rmse:0.548441\n",
      "[100]\ttrain-rmse:0.5531\tval-rmse:0.545931\n",
      "[150]\ttrain-rmse:0.551223\tval-rmse:0.545355\n",
      "[156]\ttrain-rmse:0.550955\tval-rmse:0.545248\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "[0]\ttrain-rmse:0.777075\tval-rmse:0.760285\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 50 rounds.\n",
      "[50]\ttrain-rmse:0.577271\tval-rmse:0.577693\n",
      "[100]\ttrain-rmse:0.573762\tval-rmse:0.575092\n",
      "[150]\ttrain-rmse:0.571923\tval-rmse:0.5746\n",
      "[156]\ttrain-rmse:0.57173\tval-rmse:0.574544\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "[0]\ttrain-rmse:0.822201\tval-rmse:0.820834\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 50 rounds.\n",
      "[50]\ttrain-rmse:0.581023\tval-rmse:0.589502\n",
      "[100]\ttrain-rmse:0.576989\tval-rmse:0.587105\n",
      "[150]\ttrain-rmse:0.574737\tval-rmse:0.586022\n",
      "[156]\ttrain-rmse:0.57448\tval-rmse:0.585862\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "[0]\ttrain-rmse:0.88852\tval-rmse:0.859076\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 50 rounds.\n",
      "[50]\ttrain-rmse:0.601772\tval-rmse:0.601979\n",
      "[100]\ttrain-rmse:0.597354\tval-rmse:0.59901\n",
      "[150]\ttrain-rmse:0.594837\tval-rmse:0.597967\n",
      "[156]\ttrain-rmse:0.594634\tval-rmse:0.59794\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "[0]\ttrain-rmse:0.914748\tval-rmse:0.878044\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 50 rounds.\n",
      "[50]\ttrain-rmse:0.611777\tval-rmse:0.605896\n",
      "[100]\ttrain-rmse:0.606624\tval-rmse:0.603073\n",
      "[150]\ttrain-rmse:0.604108\tval-rmse:0.601952\n",
      "[156]\ttrain-rmse:0.603854\tval-rmse:0.60183\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "[0]\ttrain-rmse:0.831787\tval-rmse:0.856231\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 50 rounds.\n",
      "[50]\ttrain-rmse:0.60373\tval-rmse:0.606752\n",
      "[100]\ttrain-rmse:0.599996\tval-rmse:0.60468\n",
      "[150]\ttrain-rmse:0.597773\tval-rmse:0.604104\n",
      "[156]\ttrain-rmse:0.597632\tval-rmse:0.604146\n",
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "[0]\ttrain-rmse:0.817208\tval-rmse:0.933431\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 50 rounds.\n",
      "[50]\ttrain-rmse:0.596974\tval-rmse:0.655623\n",
      "[100]\ttrain-rmse:0.592879\tval-rmse:0.653733\n",
      "[150]\ttrain-rmse:0.590266\tval-rmse:0.652539\n",
      "[156]\ttrain-rmse:0.590065\tval-rmse:0.652528\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "[0]\ttrain-rmse:0.817952\tval-rmse:0.903582\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 50 rounds.\n",
      "[50]\ttrain-rmse:0.586785\tval-rmse:0.633919\n",
      "[100]\ttrain-rmse:0.582153\tval-rmse:0.631966\n",
      "[150]\ttrain-rmse:0.579626\tval-rmse:0.631358\n",
      "[156]\ttrain-rmse:0.579337\tval-rmse:0.631316\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "[0]\ttrain-rmse:0.781232\tval-rmse:0.830442\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 50 rounds.\n",
      "[50]\ttrain-rmse:0.592817\tval-rmse:0.621973\n",
      "[100]\ttrain-rmse:0.588499\tval-rmse:0.620084\n",
      "[150]\ttrain-rmse:0.586512\tval-rmse:0.619903\n",
      "[156]\ttrain-rmse:0.586294\tval-rmse:0.619935\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "[0]\ttrain-rmse:0.829278\tval-rmse:0.846771\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 50 rounds.\n",
      "[50]\ttrain-rmse:0.596609\tval-rmse:0.614756\n",
      "[100]\ttrain-rmse:0.592561\tval-rmse:0.612859\n",
      "[150]\ttrain-rmse:0.590069\tval-rmse:0.611761\n",
      "[156]\ttrain-rmse:0.589833\tval-rmse:0.611624\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "[0]\ttrain-rmse:0.894069\tval-rmse:0.863499\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 50 rounds.\n",
      "[50]\ttrain-rmse:0.620618\tval-rmse:0.618404\n",
      "[100]\ttrain-rmse:0.616289\tval-rmse:0.6157\n",
      "[150]\ttrain-rmse:0.613098\tval-rmse:0.615458\n",
      "[156]\ttrain-rmse:0.61291\tval-rmse:0.61549\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "[0]\ttrain-rmse:0.916566\tval-rmse:0.886454\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 50 rounds.\n",
      "[50]\ttrain-rmse:0.629616\tval-rmse:0.628905\n",
      "[100]\ttrain-rmse:0.624185\tval-rmse:0.625814\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is an upgraded version of Ceshine's LGBM starter script, simply adding more\n",
    "average features and weekly average features on it. It also replaces LGBM with XGB. \n",
    "There is still room for improvement, but the current version is the best that can \n",
    "run in a kernel.\n",
    "\"\"\"\n",
    "from datetime import date, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "\n",
    "df_train = pd.read_csv('train.csv', usecols=[1, 2, 3, 4, 5],\n",
    "    dtype={'onpromotion': bool},\n",
    "    converters={'unit_sales': lambda u: np.log1p(\n",
    "        float(u)) if float(u) > 0 else 0},\n",
    "    parse_dates=[\"date\"],\n",
    "    skiprows=range(1, 66458909)  # 2016-01-01\n",
    ")\n",
    "\n",
    "df_test = pd.read_csv(\"test.csv\", usecols=[0, 1, 2, 3, 4],\n",
    "    dtype={'onpromotion': bool},\n",
    "    parse_dates=[\"date\"]  # , date_parser=parser\n",
    ").set_index(\n",
    "    ['store_nbr', 'item_nbr', 'date']\n",
    ")\n",
    "\n",
    "items = pd.read_csv(\"items.csv\",\n",
    ").set_index(\"item_nbr\")\n",
    "\n",
    "df_2017 = df_train.loc[df_train.date>=pd.datetime(2017,1,1)]\n",
    "del df_train\n",
    "\n",
    "promo_2017_train = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]].unstack(\n",
    "        level=-1).fillna(False)\n",
    "promo_2017_train.columns = promo_2017_train.columns.get_level_values(1)\n",
    "promo_2017_test = df_test[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
    "promo_2017_test.columns = promo_2017_test.columns.get_level_values(1)\n",
    "promo_2017_test = promo_2017_test.reindex(promo_2017_train.index).fillna(False)\n",
    "promo_2017 = pd.concat([promo_2017_train, promo_2017_test], axis=1)\n",
    "del promo_2017_test, promo_2017_train\n",
    "\n",
    "df_2017 = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(\n",
    "        level=-1).fillna(0)\n",
    "df_2017.columns = df_2017.columns.get_level_values(1)\n",
    "\n",
    "items = items.reindex(df_2017.index.get_level_values(1))\n",
    "\n",
    "def get_timespan(df, dt, minus, periods, freq='D'):\n",
    "    return df[pd.date_range(dt - timedelta(days=minus), periods=periods, freq=freq)]\n",
    "\n",
    "def prepare_dataset(t2017, is_train=True):\n",
    "    X = pd.DataFrame({\n",
    "        \"day_1_2017\": get_timespan(df_2017, t2017, 1, 1).values.ravel(),\n",
    "        \"mean_3_2017\": get_timespan(df_2017, t2017, 3, 3).mean(axis=1).values,\n",
    "        \"mean_7_2017\": get_timespan(df_2017, t2017, 7, 7).mean(axis=1).values,\n",
    "        \"mean_14_2017\": get_timespan(df_2017, t2017, 14, 14).mean(axis=1).values,\n",
    "        \"mean_30_2017\": get_timespan(df_2017, t2017, 30, 30).mean(axis=1).values,\n",
    "        \"mean_60_2017\": get_timespan(df_2017, t2017, 60, 60).mean(axis=1).values,\n",
    "        \"mean_140_2017\": get_timespan(df_2017, t2017, 140, 140).mean(axis=1).values,\n",
    "        \"promo_14_2017\": get_timespan(promo_2017, t2017, 14, 14).sum(axis=1).values,\n",
    "        \"promo_60_2017\": get_timespan(promo_2017, t2017, 60, 60).sum(axis=1).values,\n",
    "        \"promo_140_2017\": get_timespan(promo_2017, t2017, 140, 140).sum(axis=1).values\n",
    "    })\n",
    "    for i in range(7):\n",
    "        X['mean_4_dow{}_2017'.format(i)] = get_timespan(df_2017, t2017, 28-i, 4, freq='7D').mean(axis=1).values\n",
    "        X['mean_20_dow{}_2017'.format(i)] = get_timespan(df_2017, t2017, 140-i, 20, freq='7D').mean(axis=1).values\n",
    "    for i in range(16):\n",
    "        X[\"promo_{}\".format(i)] = promo_2017[\n",
    "            t2017 + timedelta(days=i)].values.astype(np.uint8)\n",
    "    if is_train:\n",
    "        y = df_2017[\n",
    "            pd.date_range(t2017, periods=16)\n",
    "        ].values\n",
    "        return X, y\n",
    "    return X\n",
    "\n",
    "print(\"Preparing dataset...\")\n",
    "t2017 = date(2017, 5, 31)\n",
    "X_l, y_l = [], []\n",
    "for i in range(6):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    X_tmp, y_tmp = prepare_dataset(\n",
    "        t2017 + delta\n",
    "    )\n",
    "    X_l.append(X_tmp)\n",
    "    y_l.append(y_tmp)\n",
    "X_train = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0)\n",
    "del X_l, y_l\n",
    "X_val, y_val = prepare_dataset(date(2017, 7, 26))\n",
    "X_test = prepare_dataset(date(2017, 8, 16), is_train=False)\n",
    "\n",
    "print(\"Training and predicting models...\")\n",
    "\n",
    "param = {}\n",
    "param['objective'] = 'reg:linear'\n",
    "param['eta'] = 0.5\n",
    "param['max_depth'] = 3\n",
    "param['silent'] = 1\n",
    "param['eval_metric'] = 'rmse'\n",
    "param['min_child_weight'] = 5\n",
    "param['subsample'] = 0.8\n",
    "param['colsample_bytree'] = 0.7\n",
    "param['seed'] = 137\n",
    "num_rounds = 157\n",
    "\n",
    "\n",
    "\n",
    "plst = list(param.items())\n",
    "\n",
    "MAX_ROUNDS = 157\n",
    "val_pred = []\n",
    "test_pred = []\n",
    "cate_vars = []\n",
    "\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "for i in range(16):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Step %d\" % (i+1))\n",
    "    print(\"=\" * 50)\n",
    "    dtrain = xgb.DMatrix(\n",
    "        X_train, label=y_train[:, i],\n",
    "        weight=pd.concat([items[\"perishable\"]] * 6) * 0.25 + 1\n",
    "    )\n",
    "    dval = xgb.DMatrix(\n",
    "        X_val, label=y_val[:, i],\n",
    "        weight=items[\"perishable\"] * 0.25 + 1)\n",
    "        \n",
    "    watchlist = [ (dtrain,'train'), (dval, 'val') ]\n",
    "    model = xgb.train(plst, dtrain, num_rounds, watchlist, early_stopping_rounds=50, verbose_eval=50)\n",
    "    \n",
    "    val_pred.append(model.predict(dval))\n",
    "    test_pred.append(model.predict(dtest))\n",
    "\n",
    "print(\"Validation mse:\", mean_squared_error(\n",
    "    y_val, np.array(val_pred).transpose()))\n",
    "\n",
    "print(\"Making submission...\")\n",
    "y_test = np.array(test_pred).transpose()\n",
    "df_preds = pd.DataFrame(\n",
    "    y_test, index=df_2017.index,\n",
    "    columns=pd.date_range(\"2017-08-16\", periods=16)\n",
    ").stack().to_frame(\"unit_sales\")\n",
    "df_preds.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
    "\n",
    "submission = df_test[[\"id\"]].join(df_preds, how=\"left\").fillna(0)\n",
    "submission[\"unit_sales\"] = np.clip(np.expm1(submission[\"unit_sales\"]), 0, 1000)\n",
    "submission.to_csv('xgb.csv', float_format='%.4f', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
